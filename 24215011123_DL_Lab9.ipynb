{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1- Task: Given a sequence of alphabets (with some missing values), use an RNN and a\n",
        "#Bidirectional RNN model to predict the missing values in the sequence.\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# STEP 1: Dataset with missing characters and their targets\n",
        "sequences_with_missing = [\n",
        "    (\"MACHINE_\", \"E\"),\n",
        "    (\"A_CHINE\", \"M\"),\n",
        "    (\"_ACHINE\", \"M\"),\n",
        "    (\"MA_HINE\", \"C\"),\n",
        "    (\"MAC_INE\", \"H\"),\n",
        "]\n",
        "\n",
        "# STEP 2: Encoding and padding\n",
        "alphabets = list(string.ascii_uppercase)\n",
        "char2idx = {char: idx + 1 for idx, char in enumerate(alphabets)}\n",
        "char2idx['_'] = 0  # placeholder for missing\n",
        "idx2char = {idx: char for char, idx in char2idx.items()}\n",
        "\n",
        "X_encoded = []\n",
        "y_encoded = []\n",
        "\n",
        "for seq, target in sequences_with_missing:\n",
        "    encoded_seq = [char2idx[char] for char in seq]\n",
        "    X_encoded.append(encoded_seq)\n",
        "    y_encoded.append(char2idx[target])\n",
        "\n",
        "# Pad sequences\n",
        "X_padded = pad_sequences(X_encoded, padding='post')\n",
        "y_encoded = np.array(y_encoded)\n",
        "\n",
        "# One-hot encode inputs and outputs\n",
        "num_classes = len(char2idx)\n",
        "seq_length = X_padded.shape[1]\n",
        "X_onehot = to_categorical(X_padded, num_classes=num_classes)\n",
        "y_onehot = to_categorical(y_encoded, num_classes=num_classes)\n",
        "\n",
        "# STEP 3: Build and train RNN\n",
        "model_rnn = Sequential([\n",
        "    SimpleRNN(64, input_shape=(seq_length, num_classes)),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.fit(X_onehot, y_onehot, epochs=100, verbose=0)\n",
        "loss_rnn, acc_rnn = model_rnn.evaluate(X_onehot, y_onehot, verbose=0)\n",
        "print(f\"âœ… RNN Training Complete - Accuracy: {acc_rnn:.2f}\")\n",
        "\n",
        "# STEP 4: Build and train Bidirectional RNN\n",
        "model_birnn = Sequential([\n",
        "    Bidirectional(SimpleRNN(64), input_shape=(seq_length, num_classes)),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model_birnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_birnn.fit(X_onehot, y_onehot, epochs=100, verbose=0)\n",
        "loss_bi, acc_bi = model_birnn.evaluate(X_onehot, y_onehot, verbose=0)\n",
        "print(f\"âœ… Bidirectional RNN Training Complete - Accuracy: {acc_bi:.2f}\")\n",
        "\n",
        "# STEP 5: Predict and compare\n",
        "def predict_and_decode(model, X_input, idx2char):\n",
        "    predictions = model.predict(X_input)\n",
        "    predicted_indices = predictions.argmax(axis=1)\n",
        "    predicted_chars = [idx2char[idx] for idx in predicted_indices]\n",
        "    return predicted_chars\n",
        "\n",
        "pred_rnn = predict_and_decode(model_rnn, X_onehot, idx2char)\n",
        "pred_birnn = predict_and_decode(model_birnn, X_onehot, idx2char)\n",
        "actual_targets = [idx2char[idx] for idx in y_encoded]\n",
        "input_sequences = [[idx2char.get(i, '_') for i in seq] for seq in X_padded]\n",
        "\n",
        "print(\"\\nğŸ“Š Prediction Comparison:\\n\")\n",
        "for i, (inp, actual, rnn_pred, birnn_pred) in enumerate(zip(input_sequences, actual_targets, pred_rnn, pred_birnn)):\n",
        "    print(f\"Seq {i+1}: {' '.join(inp)}\")\n",
        "    print(f\"  Actual Target     : {actual}\")\n",
        "    print(f\"  RNN Prediction    : {rnn_pred}\")\n",
        "    print(f\"  Bi-RNN Prediction : {birnn_pred}\\n\")\n",
        "\n",
        "# STEP 6: Save models\n",
        "model_rnn.save(\"alphabet_rnn_model.h5\")\n",
        "model_birnn.save(\"alphabet_birnn_model.h5\")\n",
        "print(\"âœ… Models saved as 'alphabet_rnn_model.h5' and 'alphabet_birnn_model.h5'\")\n"
      ],
      "metadata": {
        "id": "puGocAj8rasW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb58f2a1-0bee-4fd3-af92-88ac6bbb975d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RNN Training Complete - Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Bidirectional RNN Training Complete - Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fa27414a7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fa26f6e7b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Prediction Comparison:\n",
            "\n",
            "Seq 1: M A C H I N E _\n",
            "  Actual Target     : E\n",
            "  RNN Prediction    : E\n",
            "  Bi-RNN Prediction : E\n",
            "\n",
            "Seq 2: A _ C H I N E _\n",
            "  Actual Target     : M\n",
            "  RNN Prediction    : M\n",
            "  Bi-RNN Prediction : M\n",
            "\n",
            "Seq 3: _ A C H I N E _\n",
            "  Actual Target     : M\n",
            "  RNN Prediction    : M\n",
            "  Bi-RNN Prediction : M\n",
            "\n",
            "Seq 4: M A _ H I N E _\n",
            "  Actual Target     : C\n",
            "  RNN Prediction    : C\n",
            "  Bi-RNN Prediction : C\n",
            "\n",
            "Seq 5: M A C _ I N E _\n",
            "  Actual Target     : H\n",
            "  RNN Prediction    : H\n",
            "  Bi-RNN Prediction : H\n",
            "\n",
            "âœ… Models saved as 'alphabet_rnn_model.h5' and 'alphabet_birnn_model.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Create large dataset of synthetic alphabet sequences\n",
        "def generate_sequences(num_samples=500):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        # Random sequence of length 7-8 with no duplicates\n",
        "        seq_length = random.choice([7, 8])\n",
        "        full_seq = random.sample(string.ascii_uppercase, seq_length)\n",
        "\n",
        "        # Randomly remove 1 char\n",
        "        missing_index = random.randint(0, len(full_seq) - 1)\n",
        "        missing_char = full_seq[missing_index]\n",
        "        full_seq[missing_index] = '_'  # Replace with placeholder\n",
        "\n",
        "        sequence_str = ''.join(full_seq)\n",
        "        data.append((sequence_str, missing_char))\n",
        "    return data\n",
        "\n",
        "# Generate big dataset\n",
        "sequences_with_missing = generate_sequences(500)\n",
        "\n",
        "# Step 2: Preprocessing\n",
        "char2idx = {char: idx + 1 for idx, char in enumerate(string.ascii_uppercase)}\n",
        "char2idx['_'] = 0\n",
        "idx2char = {idx: char for char, idx in char2idx.items()}\n",
        "\n",
        "X_encoded = []\n",
        "y_encoded = []\n",
        "\n",
        "for seq, target in sequences_with_missing:\n",
        "    encoded_seq = [char2idx[char] for char in seq]\n",
        "    X_encoded.append(encoded_seq)\n",
        "    y_encoded.append(char2idx[target])\n",
        "\n",
        "# Pad sequences to max length\n",
        "X_padded = pad_sequences(X_encoded, padding='post')\n",
        "y_encoded = np.array(y_encoded)\n",
        "\n",
        "# One-hot encode inputs and targets\n",
        "num_classes = len(char2idx)\n",
        "seq_length = X_padded.shape[1]\n",
        "X_onehot = to_categorical(X_padded, num_classes=num_classes)\n",
        "y_onehot = to_categorical(y_encoded, num_classes=num_classes)\n",
        "\n",
        "# Step 3: Build & train RNN model\n",
        "model_rnn = Sequential([\n",
        "    SimpleRNN(64, input_shape=(seq_length, num_classes)),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.fit(X_onehot, y_onehot, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 4: Build & train Bidirectional RNN model\n",
        "model_birnn = Sequential([\n",
        "    Bidirectional(SimpleRNN(64), input_shape=(seq_length, num_classes)),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model_birnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_birnn.fit(X_onehot, y_onehot, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 5: Evaluate both models\n",
        "loss_rnn, acc_rnn = model_rnn.evaluate(X_onehot, y_onehot, verbose=0)\n",
        "loss_birnn, acc_birnn = model_birnn.evaluate(X_onehot, y_onehot, verbose=0)\n",
        "print(f\"âœ… RNN Accuracy: {acc_rnn:.2f}\")\n",
        "print(f\"âœ… Bi-RNN Accuracy: {acc_birnn:.2f}\")\n",
        "\n",
        "# Step 6: Save models\n",
        "model_rnn.save(\"alphabet_rnn_model.h5\")\n",
        "model_birnn.save(\"alphabet_birnn_model.h5\")\n",
        "print(\"âœ… Models saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr1PXhtguIBt",
        "outputId": "309dd2e0-4d31-4d45-850d-851c3bae6a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0385 - loss: 3.3554\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0694 - loss: 3.2401\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0812 - loss: 3.1854\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1008 - loss: 3.1097\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1458 - loss: 3.0320\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1732 - loss: 2.9465\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2407 - loss: 2.8688\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2132 - loss: 2.8418\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2418 - loss: 2.7572\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2783 - loss: 2.6927\n",
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0511 - loss: 3.3476\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0980 - loss: 3.1945\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1548 - loss: 3.0647\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2123 - loss: 2.9781\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2623 - loss: 2.8442\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3244 - loss: 2.7195\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3253 - loss: 2.6220\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3978 - loss: 2.4703\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4380 - loss: 2.3830\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4697 - loss: 2.2743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RNN Accuracy: 0.29\n",
            "âœ… Bi-RNN Accuracy: 0.51\n",
            "âœ… Models saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgUClQ5BrGDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Create dataset\n",
        "def create_dataset():\n",
        "    alphabet = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "    sequence = (['A', 'B', 'C', '?', 'E', 'F', 'G', '?', 'I', 'J', 'K', 'L',\n",
        "                '?', 'N', 'O', 'P', 'Q', 'R', '?', 'T', 'U', 'V', 'W', 'X',\n",
        "                'Y', '?'] * 2 +\n",
        "                ['A', '?', 'C', 'D', 'E', '?', 'G', 'H', 'I', '?', 'K', 'L',\n",
        "                'M', 'N', '?', 'P', 'Q', 'R', 'S', 'T', '?', 'V', 'W', 'X',\n",
        "                'Y', 'Z'])\n",
        "    return sequence, alphabet\n",
        "\n",
        "# Step 2: Preprocess data (Fixed)\n",
        "def preprocess_data(sequence, alphabet, seq_length=6):\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(alphabet)\n",
        "\n",
        "    # Replace '?' with a special token (0) and encode valid characters\n",
        "    encoded_seq = [encoder.transform([c])[0] if c != '?' else 0 for c in sequence]\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(encoded_seq) - seq_length):\n",
        "        window = encoded_seq[i:i + seq_length]\n",
        "        target = encoded_seq[i + seq_length]\n",
        "\n",
        "        if 0 not in window:  # Only train on fully known sequences\n",
        "            X.append(window)\n",
        "            y.append(target)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y).reshape(-1, 1)  # Ensure `y` has the correct shape\n",
        "\n",
        "    return X, y, encoder, encoded_seq\n",
        "\n",
        "# Step 3: Build LSTM Model\n",
        "def build_lstm_model(input_dim, embedding_dim=16, lstm_units=128):\n",
        "    inputs = Input(shape=(None,))\n",
        "    embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim, mask_zero=True)(inputs)\n",
        "    lstm = LSTM(lstm_units, return_sequences=False)(embedding)\n",
        "    outputs = Dense(input_dim, activation='softmax')(lstm)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Step 4: Predict missing values\n",
        "def predict_sequence(model, sequence, encoder, encoded_seq, seq_length=6):\n",
        "    predictions = sequence.copy()\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] == '?':\n",
        "            context_window = []\n",
        "            for j in range(i - seq_length, i):\n",
        "                if j < 0 or predictions[j] == '?':\n",
        "                    context_window.append(0)  # Padding for unknown values\n",
        "                else:\n",
        "                    context_window.append(encoder.transform([predictions[j]])[0])\n",
        "\n",
        "            context_window = np.array(context_window).reshape(1, seq_length)\n",
        "\n",
        "            pred = model.predict(context_window, verbose=0)\n",
        "            predicted_idx = np.argmax(pred)\n",
        "            predicted_char = encoder.inverse_transform([predicted_idx])[0]\n",
        "\n",
        "            predictions[i] = predicted_char\n",
        "            encoded_seq[i] = predicted_idx\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    sequence, alphabet = create_dataset()\n",
        "    X, y, encoder, encoded_seq = preprocess_data(sequence, alphabet)\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(\"Error: No valid training sequences found\")\n",
        "        return\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y = tf.keras.utils.to_categorical(y, num_classes=len(alphabet))\n",
        "\n",
        "    # Split data\n",
        "    split = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    # Build and train LSTM model\n",
        "    model = build_lstm_model(input_dim=len(alphabet))\n",
        "    print(\"Training LSTM model...\")\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "    # Predict missing values\n",
        "    print(\"\\nOriginal sequence:\", ' '.join(sequence))\n",
        "    lstm_predictions = predict_sequence(model, sequence, encoder, encoded_seq)\n",
        "\n",
        "    print(\"LSTM predictions:\", ' '.join(lstm_predictions))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwHkVIbpJ7oZ",
        "outputId": "a09af09e-1666-4fcc-87ac-ac22601076b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 3.2617 - val_accuracy: 1.0000 - val_loss: 3.2451\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 3.2451 - val_accuracy: 1.0000 - val_loss: 3.2281\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 3.2281 - val_accuracy: 1.0000 - val_loss: 3.2099\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 3.2099 - val_accuracy: 1.0000 - val_loss: 3.1900\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.1900 - val_accuracy: 1.0000 - val_loss: 3.1677\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 3.1677 - val_accuracy: 1.0000 - val_loss: 3.1422\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 3.1422 - val_accuracy: 1.0000 - val_loss: 3.1130\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 3.1130 - val_accuracy: 1.0000 - val_loss: 3.0792\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 3.0792 - val_accuracy: 1.0000 - val_loss: 3.0397\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 3.0397 - val_accuracy: 1.0000 - val_loss: 2.9936\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 2.9936 - val_accuracy: 1.0000 - val_loss: 2.9392\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.9392 - val_accuracy: 1.0000 - val_loss: 2.8750\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.8750 - val_accuracy: 1.0000 - val_loss: 2.7990\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 2.7990 - val_accuracy: 1.0000 - val_loss: 2.7085\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 2.7085 - val_accuracy: 1.0000 - val_loss: 2.6005\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 2.6005 - val_accuracy: 1.0000 - val_loss: 2.4715\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.4715 - val_accuracy: 1.0000 - val_loss: 2.3172\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3172 - val_accuracy: 1.0000 - val_loss: 2.1327\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 2.1327 - val_accuracy: 1.0000 - val_loss: 1.9129\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.9129 - val_accuracy: 1.0000 - val_loss: 1.6538\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 1.6538 - val_accuracy: 1.0000 - val_loss: 1.3543\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.3543 - val_accuracy: 1.0000 - val_loss: 1.0225\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 1.0225 - val_accuracy: 1.0000 - val_loss: 0.6831\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 0.6831 - val_accuracy: 1.0000 - val_loss: 0.3832\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.3832 - val_accuracy: 1.0000 - val_loss: 0.1733\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1733 - val_accuracy: 1.0000 - val_loss: 0.0638\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 1.0000 - val_loss: 0.0205\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 6.0504e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.0504e-04 - val_accuracy: 1.0000 - val_loss: 2.0931e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.0931e-04 - val_accuracy: 1.0000 - val_loss: 7.9509e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 7.9509e-05 - val_accuracy: 1.0000 - val_loss: 3.3140e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 3.3140e-05 - val_accuracy: 1.0000 - val_loss: 1.5259e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 1.5259e-05 - val_accuracy: 1.0000 - val_loss: 7.3909e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 7.3909e-06 - val_accuracy: 1.0000 - val_loss: 4.0531e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 4.0531e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 2.3842e-06 - val_accuracy: 1.0000 - val_loss: 1.5497e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 1.5497e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-07\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 8.3446e-07 - val_accuracy: 1.0000 - val_loss: 5.9605e-07\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 5.9605e-07 - val_accuracy: 1.0000 - val_loss: 4.7684e-07\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 4.7684e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 3.5763e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 2.3842e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "\n",
            "Original sequence: A B C ? E F G ? I J K L ? N O P Q R ? T U V W X Y ? A B C ? E F G ? I J K L ? N O P Q R ? T U V W X Y ? A ? C D E ? G H I ? K L M N ? P Q R S T ? V W X Y Z\n",
            "LSTM predictions: A B C A E F G A I J K L A N O P Q R A T U V W X Y A A B C A E F G A I J K L A N O P Q R A T U V W X Y A A A C D E A G H I A K L M N A P Q R S T A V W X Y Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cu4Eaup8NCtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the next word in a sentence using an RNN. Consider the following sentence\n",
        "dataset:\n",
        "The cat sat on the mat.\n",
        "The dog sat on the rug.\n",
        "The bird flew in the sky.\n",
        "The cat jumped over the fence.\n",
        "And predict â€œThe cat sat on __-â€œ\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. Dataset\n",
        "sentences = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"The dog sat on the rug\",\n",
        "    \"The bird flew in the sky\",\n",
        "    \"The cat jumped over the fence\"\n",
        "]\n",
        "\n",
        "# 1. Text Preprocessing\n",
        "def preprocess_data(sentences):\n",
        "    # Tokenize the text\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    # Convert sentences to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "    # Create input-output pairs\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append(seq[:i])\n",
        "            y.append(seq[i])\n",
        "\n",
        "    # Pad sequences to ensure uniform length\n",
        "    max_length = max(len(seq) for seq in X)\n",
        "    X = pad_sequences(X, maxlen=max_length, padding='pre')\n",
        "\n",
        "    # Convert y to one-hot encoding\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y, tokenizer, max_length, vocab_size\n",
        "\n",
        "# 2. Model Building\n",
        "def build_model(vocab_size, max_length):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 10, input_length=max_length),\n",
        "        SimpleRNN(50, return_sequences=False),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 3. Training and Prediction\n",
        "def train_and_predict(sentences, predict_sentence=\"The cat sat on\"):\n",
        "    # Preprocess data\n",
        "    X, y, tokenizer, max_length, vocab_size = preprocess_data(sentences)\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_model(vocab_size, max_length)\n",
        "    model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "    # Prepare prediction input\n",
        "    predict_seq = tokenizer.texts_to_sequences([predict_sentence])[0]\n",
        "    predict_seq = pad_sequences([predict_seq], maxlen=max_length, padding='pre')\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(predict_seq, verbose=0)\n",
        "    predicted_word_idx = np.argmax(prediction[0])\n",
        "    predicted_word = tokenizer.index_word[predicted_word_idx]\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Train and predict\n",
        "    predicted_word = train_and_predict(sentences)\n",
        "\n",
        "    print(f\"Input sentence: 'The cat sat on'\")\n",
        "    print(f\"Predicted next word: {predicted_word}\")\n",
        "    print(f\"Complete prediction: 'The cat sat on {predicted_word}'\")\n",
        "\n",
        "    # Show the vocabulary\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    print(\"\\nVocabulary:\", tokenizer.word_index)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVVi3k3eNC7r",
        "outputId": "200af0dc-e99c-4a53-b087-d3527a05a458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence: 'The cat sat on'\n",
            "Predicted next word: the\n",
            "Complete prediction: 'The cat sat on the'\n",
            "\n",
            "Vocabulary: {'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'rug': 7, 'bird': 8, 'flew': 9, 'in': 10, 'sky': 11, 'jumped': 12, 'over': 13, 'fence': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##3- Develop a sequence generator for Indian Classical Music Raga using an RNN to predict the\n",
        "#next note in a series. The notes involved are Sa, Re, Ga, Ma, Pa, Dha, Ni, and Sha.\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import random\n",
        "\n",
        "# 1. Dataset Preparation\n",
        "# Define basic notes\n",
        "notes = ['Sa', 'Re', 'Ga', 'Ma', 'Pa', 'Dha', 'Ni', 'Sha']\n",
        "\n",
        "# Define specific raga scales (simplified versions)\n",
        "raga_scales = {\n",
        "    'Bhairav': ['Sa', 'Re', 'Ga', 'Ma', 'Pa', 'Dha', 'Ni'],\n",
        "    'Bhopali': ['Sa', 'Re', 'Ga', 'Pa', 'Dha'],\n",
        "    'Bageshree': ['Sa', 'Ga', 'Ma', 'Dha', 'Ni']\n",
        "}\n",
        "\n",
        "# 2. Preprocess Data\n",
        "def create_sequences(scale, sequence_length=5, num_sequences=100):\n",
        "    # Convert notes to numerical values\n",
        "    note_to_int = {note: i for i, note in enumerate(scale)}\n",
        "    int_to_note = {i: note for i, note in enumerate(scale)}\n",
        "\n",
        "    # Generate random sequences\n",
        "    sequences = []\n",
        "    next_notes = []\n",
        "\n",
        "    for _ in range(num_sequences):\n",
        "        start_idx = random.randint(0, len(scale) - sequence_length)\n",
        "        seq = scale[start_idx:start_idx + sequence_length]\n",
        "        next_note = scale[(start_idx + sequence_length) % len(scale)]\n",
        "\n",
        "        sequences.append([note_to_int[note] for note in seq])\n",
        "        next_notes.append(note_to_int[next_note])\n",
        "\n",
        "    return np.array(sequences), np.array(next_notes), note_to_int, int_to_note\n",
        "\n",
        "# 3. Model Building\n",
        "def build_model(input_shape, num_notes):\n",
        "    model = Sequential([\n",
        "        LSTM(128, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(64),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(num_notes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "# 4. Training and Generation\n",
        "def train_and_generate(raga_name, epochs=20, sequence_length=5, generate_length=20):\n",
        "    # Prepare data\n",
        "    scale = raga_scales.get(raga_name, notes)  # Default to full scale if raga not found\n",
        "    X, y, note_to_int, int_to_note = create_sequences(scale, sequence_length)\n",
        "\n",
        "    # Reshape input for LSTM [samples, timesteps, features]\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_model((sequence_length, 1), len(scale))\n",
        "    model.fit(X, y, epochs=epochs, batch_size=32, verbose=1)\n",
        "\n",
        "    # Generate sequence\n",
        "    def generate_sequence(model, seed_sequence, length):\n",
        "        generated = seed_sequence.copy()\n",
        "\n",
        "        for _ in range(length):\n",
        "            x_pred = np.array(generated[-sequence_length:]).reshape(1, sequence_length, 1)\n",
        "            prediction = model.predict(x_pred, verbose=0)\n",
        "            next_note = np.argmax(prediction)\n",
        "            generated.append(next_note)\n",
        "\n",
        "        return [int_to_note[i] for i in generated]\n",
        "\n",
        "    # Generate a sequence\n",
        "    seed_idx = random.randint(0, len(X) - 1)\n",
        "    seed_sequence = X[seed_idx, :, 0].tolist()\n",
        "    generated_sequence = generate_sequence(model, seed_sequence, generate_length)\n",
        "\n",
        "    return generated_sequence\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    ragas_to_generate = ['Bhairav', 'Bhopali', 'Bageshree']\n",
        "\n",
        "    print(\"Generating Raga Sequences:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for raga in ragas_to_generate:\n",
        "        print(f\"\\nRaga {raga}:\")\n",
        "        sequence = train_and_generate(raga, epochs=10)\n",
        "        print(\"Generated sequence:\", \" -> \".join(sequence))\n",
        "\n",
        "        # Print the scale used\n",
        "        print(f\"Scale used: {', '.join(raga_scales[raga])}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHMLNhdCNf1t",
        "outputId": "4c37b1db-cffd-4ed4-d4b3-ea751742ad5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Raga Sequences:\n",
            "--------------------------------------------------\n",
            "\n",
            "Raga Bhairav:\n",
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.9417\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8027\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7048\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6088\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4700\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4568\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3678\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2316\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1901\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0153\n",
            "Generated sequence: Sa -> Re -> Ga -> Ma -> Pa -> Dha -> Sa -> Sa -> Sa -> Sa -> Sa -> Dha -> Dha -> Dha -> Sa -> Sa -> Sa -> Sa -> Sa -> Dha -> Dha -> Dha -> Sa -> Sa -> Sa\n",
            "Scale used: Sa, Re, Ga, Ma, Pa, Dha, Ni\n",
            "\n",
            "Raga Bhopali:\n",
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 1.5455\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2566\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8940\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4700\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1274\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0200\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.6723e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5198e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5510e-04\n",
            "Generated sequence: Sa -> Re -> Ga -> Pa -> Dha -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa\n",
            "Scale used: Sa, Re, Ga, Pa, Dha\n",
            "\n",
            "Raga Bageshree:\n",
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 1.5397\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2726\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9534\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5448\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1958\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0404\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0020\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.4831e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.0126e-04\n",
            "Generated sequence: Sa -> Ga -> Ma -> Dha -> Ni -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa -> Sa\n",
            "Scale used: Sa, Ga, Ma, Dha, Ni\n"
          ]
        }
      ]
    }
  ]
}