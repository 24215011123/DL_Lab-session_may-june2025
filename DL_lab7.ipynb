{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# \"Image Classification Using CIFAR-10 Dataset using simple deep network with 4 hidden layers and 3 dropout layer also apply pruning and quantization\n",
        "to reduce size and report size of model\""
      ],
      "metadata": {
        "id": "EahjlcHP7m-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVR5J1kW8qHA",
        "outputId": "b4df73d9-5533-433c-deb5-d25427001573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 32s 39ms/step - loss: 2.0457 - accuracy: 0.2373 - val_loss: 1.8939 - val_accuracy: 0.3063\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.8857 - accuracy: 0.3052 - val_loss: 1.8209 - val_accuracy: 0.3581\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.8362 - accuracy: 0.3281 - val_loss: 1.7524 - val_accuracy: 0.3769\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.8113 - accuracy: 0.3356 - val_loss: 1.7117 - val_accuracy: 0.3881\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 1.7911 - accuracy: 0.3478 - val_loss: 1.7169 - val_accuracy: 0.4004\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 31s 39ms/step - loss: 1.7628 - accuracy: 0.3581 - val_loss: 1.6632 - val_accuracy: 0.4173\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.7465 - accuracy: 0.3653 - val_loss: 1.6448 - val_accuracy: 0.4183\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.7359 - accuracy: 0.3714 - val_loss: 1.6408 - val_accuracy: 0.4304\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.7209 - accuracy: 0.3754 - val_loss: 1.6236 - val_accuracy: 0.4229\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 1.7155 - accuracy: 0.3772 - val_loss: 1.6561 - val_accuracy: 0.4145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Size: 20.04 MB\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 39s 44ms/step - loss: 2.0200 - accuracy: 0.2512 - val_loss: 1.8009 - val_accuracy: 0.3508\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 32s 40ms/step - loss: 1.8284 - accuracy: 0.3353 - val_loss: 1.7247 - val_accuracy: 0.3806\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 32s 41ms/step - loss: 1.7725 - accuracy: 0.3576 - val_loss: 1.6699 - val_accuracy: 0.3980\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 32s 40ms/step - loss: 1.7361 - accuracy: 0.3748 - val_loss: 1.6320 - val_accuracy: 0.4163\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 1.7018 - accuracy: 0.3845 - val_loss: 1.6031 - val_accuracy: 0.4301\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 32s 41ms/step - loss: 1.6715 - accuracy: 0.3952 - val_loss: 1.6004 - val_accuracy: 0.4300\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 32s 41ms/step - loss: 1.6480 - accuracy: 0.4057 - val_loss: 1.5623 - val_accuracy: 0.4360\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 34s 44ms/step - loss: 1.6276 - accuracy: 0.4147 - val_loss: 1.5417 - val_accuracy: 0.4496\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 1.6138 - accuracy: 0.4180 - val_loss: 1.5208 - val_accuracy: 0.4563\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 1.5943 - accuracy: 0.4244 - val_loss: 1.5239 - val_accuracy: 0.4535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model Size: 6.69 MB\n",
            "Quantized Model Size: 1.68 MB\n",
            "\n",
            "Model Size Comparison:\n",
            "Original Model: 20.04 MB\n",
            "Pruned Model (After Stripping): 6.69 MB\n",
            "Quantized Model: 1.68 MB\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot  # For pruning and quantization\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# Load and Preprocess CIFAR-10 Dataset\n",
        "# -------------------------------\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values (0 to 1)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# -------------------------------\n",
        "#  Build a Simple Deep Neural Network (DNN)\n",
        "# -------------------------------\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')  # 10 classes (CIFAR-10)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "original_model = create_model()\n",
        "original_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# -------------------------------\n",
        "# Train the Original Model\n",
        "# -------------------------------\n",
        "original_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=64)\n",
        "\n",
        "# Save original model and get size\n",
        "original_model.save('original_model.h5')\n",
        "original_model_size = os.path.getsize('original_model.h5') / (1024 * 1024)  # Convert to MB\n",
        "print(f\"Original Model Size: {original_model_size:.2f} MB\")\n",
        "\n",
        "# -------------------------------\n",
        "# Apply Pruning to Reduce Parameters\n",
        "# -------------------------------\n",
        "pruning_params = {\n",
        "    \"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(\n",
        "        initial_sparsity=0.20, final_sparsity=0.80, begin_step=0, end_step=1000\n",
        "    )\n",
        "}\n",
        "\n",
        "# Apply pruning wrapper\n",
        "pruned_model = tf.keras.Sequential([\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Flatten(input_shape=(32, 32, 3)), **pruning_params),\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(512, activation='relu'), **pruning_params),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(256, activation='relu'), **pruning_params),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(128, activation='relu'), **pruning_params),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(64, activation='relu'), **pruning_params),\n",
        "    tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Dense(10, activation='softmax'), **pruning_params)\n",
        "])\n",
        "\n",
        "# Compile pruned model\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the pruned model with pruning callback\n",
        "pruned_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    batch_size=64,\n",
        "    callbacks=[tfmot.sparsity.keras.UpdatePruningStep()]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Remove pruning wrappers before saving\n",
        "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "stripped_pruned_model.save('pruned_model.h5')\n",
        "\n",
        "# Get pruned model size\n",
        "pruned_model_size = os.path.getsize('pruned_model.h5') / (1024 * 1024)\n",
        "print(f\"Pruned Model Size: {pruned_model_size:.2f} MB\")\n",
        "\n",
        "# -------------------------------\n",
        "# Apply Quantization for Further Compression\n",
        "# -------------------------------\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_pruned_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Apply full quantization\n",
        "\n",
        "quantized_model = converter.convert()\n",
        "\n",
        "# Save quantized model\n",
        "quantized_model_path = 'quantized_model.tflite'\n",
        "with open(quantized_model_path, 'wb') as f:\n",
        "    f.write(quantized_model)\n",
        "\n",
        "# Get quantized model size\n",
        "quantized_model_size = os.path.getsize(quantized_model_path) / (1024 * 1024)\n",
        "print(f\"Quantized Model Size: {quantized_model_size:.2f} MB\")\n",
        "\n",
        "# -------------------------------\n",
        "# Compare Model Sizes\n",
        "# -----------------------------\n",
        "print(\"\\nModel Size Comparison:\")\n",
        "print(f\"Original Model: {original_model_size:.2f} MB\")\n",
        "print(f\"Pruned Model (After Stripping): {pruned_model_size:.2f} MB\")\n",
        "print(f\"Quantized Model: {quantized_model_size:.2f} MB\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}